{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/AminMohamed-3/Emotion-Classification.git\n!pip install transformers dataset accelerate -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-17T12:43:54.793800Z","iopub.execute_input":"2024-05-17T12:43:54.794172Z","iopub.status.idle":"2024-05-17T12:44:08.481018Z","shell.execute_reply.started":"2024-05-17T12:43:54.794139Z","shell.execute_reply":"2024-05-17T12:44:08.479889Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"fatal: destination path 'Emotion-Classification' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/Emotion-Classification\")\n\nimport torch\nfrom Training.dataset import prepare_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nfrom config import NUM_LABELS","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:44:08.482806Z","iopub.execute_input":"2024-05-17T12:44:08.483127Z","iopub.status.idle":"2024-05-17T12:44:15.754814Z","shell.execute_reply.started":"2024-05-17T12:44:08.483098Z","shell.execute_reply":"2024-05-17T12:44:15.754003Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Define the model & Prepare Dataset","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"distilbert/distilroberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_checkpoint, num_labels=NUM_LABELS\n)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:44:22.149907Z","iopub.execute_input":"2024-05-17T12:44:22.150454Z","iopub.status.idle":"2024-05-17T12:44:27.044822Z","shell.execute_reply.started":"2024-05-17T12:44:22.150422Z","shell.execute_reply":"2024-05-17T12:44:27.043977Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2a86b760c924685b7a95082813b57bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1541343d232943ffa39046dd38d4f24f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9495df14b46e48208bc7d66fa52e8f5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06ad83d0952d4ea18ab9999d565d76d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7473f339355946398ffd2ff205d39936"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ecd38a8fc054caba71203b5e10dbee4"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = prepare_dataset(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:44:28.165919Z","iopub.execute_input":"2024-05-17T12:44:28.167210Z","iopub.status.idle":"2024-05-17T12:44:56.386421Z","shell.execute_reply.started":"2024-05-17T12:44:28.167173Z","shell.execute_reply":"2024-05-17T12:44:56.385385Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/9.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe246e91f3d44f8c9501337b5066604c"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 24.8M/24.8M [00:00<00:00, 108MB/s] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/211225 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21a027036c074aebb228046ee388373c"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 211225/211225 [00:04<00:00, 44164.58it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/168980 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee463ba46f504f1e848dd85203822277"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21122 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c46eb124def42fda9f471c3ae132d76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21123 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6256d81a684646a948735d4e53b333"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer, padding=True)\n\n# Define the training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=5e-5,\n    save_total_limit=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_f1\",\n    greater_is_better=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:49:27.841536Z","iopub.execute_input":"2024-05-17T12:49:27.841910Z","iopub.status.idle":"2024-05-17T12:49:38.013146Z","shell.execute_reply.started":"2024-05-17T12:49:27.841883Z","shell.execute_reply":"2024-05-17T12:49:38.012332Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-05-17 12:49:29.707914: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-17 12:49:29.708011: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-17 12:49:29.860398: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import (\n    precision_score,\n    recall_score,\n    f1_score,\n    accuracy_score,\n    hamming_loss,\n    roc_curve,\n)\n\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions\n    threshold = 0.5\n\n    preds = (preds > threshold).astype(int)\n\n    precision_micro = precision_score(labels, preds, average=\"macro\", zero_division=0)\n    recall_micro = recall_score(labels, preds, average=\"macro\", zero_division=0)\n    f1_micro = f1_score(labels, preds, average=\"macro\", zero_division=0)\n    accuracy = accuracy_score(labels, preds)\n\n    # Add the expected keys\n    metrics = {\n        \"precision_micro\": precision_micro,\n        \"recall_micro\": recall_micro,\n        \"eval_accuracy\": accuracy,  # For Hugging Face Trainer\n        \"eval_f1\": f1_micro,  # For Hugging Face Trainer\n    }\n\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:49:38.014638Z","iopub.execute_input":"2024-05-17T12:49:38.014989Z","iopub.status.idle":"2024-05-17T12:49:38.022162Z","shell.execute_reply.started":"2024-05-17T12:49:38.014963Z","shell.execute_reply":"2024-05-17T12:49:38.021127Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class MultiLabelTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        labels = labels[:, :NUM_LABELS].float()\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        loss = loss_fn(logits, labels)\n        return (loss, outputs) if return_outputs else loss\n\n\ntrainer = MultiLabelTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"val\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:49:38.023378Z","iopub.execute_input":"2024-05-17T12:49:38.023738Z","iopub.status.idle":"2024-05-17T12:49:38.707685Z","shell.execute_reply.started":"2024-05-17T12:49:38.023705Z","shell.execute_reply":"2024-05-17T12:49:38.706929Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:49:38.709245Z","iopub.execute_input":"2024-05-17T12:49:38.709508Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_125014-qx15qfw7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/0ssamaak0/huggingface/runs/qx15qfw7' target=\"_blank\">bumbling-wildflower-6</a></strong> to <a href='https://wandb.ai/0ssamaak0/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/0ssamaak0/huggingface' target=\"_blank\">https://wandb.ai/0ssamaak0/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/0ssamaak0/huggingface/runs/qx15qfw7' target=\"_blank\">https://wandb.ai/0ssamaak0/huggingface/runs/qx15qfw7</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1590' max='7923' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1590/7923 24:51 < 1:39:07, 1.06 it/s, Epoch 0.60/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]}]}