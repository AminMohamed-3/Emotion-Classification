{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dataset_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211225/211225 [00:13<00:00, 16216.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"go_emotions\", \"raw\")\n",
    "dataset.set_format(type=\"pandas\")\n",
    "df_train = dataset[\"train\"][:]\n",
    "\n",
    "emotions = list(df_train.columns)[9:]\n",
    "columns = [\"text\"] + emotions\n",
    "# select only texts and emotions\n",
    "df_train = df_train[columns]\n",
    "\n",
    "\n",
    "# create new column with list of emotions (in strings)\n",
    "df_train[\"ds_emotions\"] = df_train[emotions].progress_apply(\n",
    "    lambda x: x.index[x == 1].tolist(), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "samples = df_train[df_train[\"ds_emotions\"].apply(lambda x: \"neutral\" in x)]\n",
    "samples = samples.sample(20, random_state=7102023)\n",
    "# drop emotions columns\n",
    "samples = samples.drop(emotions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "# LLM Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "SYSTEM_MESSAGE = \"You're an AI expert trained to analyze and categorize emotions present in text. Your goal is to analyze each piece of text according to instructions\"\n",
    "\n",
    "PROMPT_TEMPLATE = f\"\"\"\n",
    "Given: {{comment}}\n",
    "Emotion list: {emotions}\n",
    "Perform an emotional analysis of the comment to by following these steps:\n",
    "\n",
    "Literal analysis: Identify emotions directly expressed through obvious emotional words/phrases.\n",
    "Contextual analysis: Consider the full context and implications to detect any additional underlying emotions.\n",
    "Tonal analysis: Examine tone, subtext, and nuanced emotional cues beyond the literal language.\n",
    "\n",
    "You may only pick one, two or three classes.\n",
    "\n",
    "For each level of analysis, provide your findings.\n",
    "Then, summarize by listing the emotion class(es) that apply in <answer> (classes) </answer>. Use \"neutral\" ONLY if no emotions from the list are detected.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYSTEM_MESSAGE),\n",
    "        # few_shot_prompt,\n",
    "        (\"human\", PROMPT_TEMPLATE),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "groq_api = \"\"\n",
    "openai_api = \"\"\n",
    "fireworks_api = \"r8qFN4YhAZwBHev6fizSxvcny30f7Y9JuGUQwqXKdMi1N0se\"\n",
    "\n",
    "# Define models\n",
    "chat1 = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model_name=\"accounts/fireworks/models/llama-v3-70b-instruct\",\n",
    "    openai_api_base=\"https://api.fireworks.ai/inference/v1\",\n",
    "    openai_api_key=fireworks_api,\n",
    ")\n",
    "\n",
    "chain1 = final_prompt | chat1 | StrOutputParser()\n",
    "\n",
    "# chat2 = ChatOpenAI(api_key=openai_api)\n",
    "\n",
    "# chain2 = final_prompt | chat2 | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "samples[\"fireworks\"] = None\n",
    "# for index in range(len(samples)):\n",
    "for index in tqdm(samples.index):\n",
    "    comment = samples.loc[index][\"text\"]\n",
    "    label = samples.loc[index][\"ds_emotions\"]\n",
    "    response1 = chain1.invoke({\"comment\": comment})\n",
    "    extracted_emotions = extract_emotions(response1)\n",
    "    samples.at[index, \"fireworks\"] = extracted_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[\"ground_truth\"] = [\n",
    "    [\"optimism\",\"excitement\"],\n",
    "    [\"embarrassment\"],\n",
    "    [\"approval\",\"admiration\"],\n",
    "    [\"disapproval\",\"annoyance\"],\n",
    "    [\"annoyance\",\"disgust\"],\n",
    "    [\"remorse\",\"sadness\"],\n",
    "    [\"disapproval\"],\n",
    "    [\"caring\"],\n",
    "    [\"disapproval\",\"annoyance\"],\n",
    "    [\"disapproval\",],\n",
    "    [\"amusment\",\"confusion\"],\n",
    "    [\"neutral\"],\n",
    "    [\"caring\"],\n",
    "    [\"approval\"],\n",
    "    [\"neutral\"],\n",
    "    [\"excitement\"],\n",
    "    [\"realization\", \"disappintment\"],\n",
    "    [\"disapproval\"],\n",
    "    [\"sadness\"],\n",
    "    [\"neutral\"],\n",
    "]\n",
    "gt = samples[[\"text\", \"ground_truth\"]]\n",
    "gt.to_csv(\"ground_truth.csv\", index=True)\n",
    "samples.to_csv(\"samples.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input\n",
    "samples = pd.read_csv(\"samples.csv\")\n",
    "predicted_labels = samples[\"fireworks\"]\n",
    "\n",
    "scores, average_bce = process_and_score(predicted_labels, samples[\"ground_truth\"], emotions)\n",
    "\n",
    "save_results_to_csv(scores, 'results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[\"fireworks_70b_prompt1_T.5\"] = [['optimism', 'excitement'],\n",
    " ['amusement', 'embarrassment'],\n",
    " ['admiration', 'gratitude', 'approval'],\n",
    " ['annoyance', 'disapproval'],\n",
    " ['amusement', 'annoyance'],\n",
    " ['disappointment', 'sadness'],\n",
    " ['amusement', 'annoyance'],\n",
    " ['caring', 'relief'],\n",
    " ['annoyance', 'love'],\n",
    " ['annoyance', 'skepticism'],\n",
    " ['approval', 'annoyance'],\n",
    " ['neutral'],\n",
    " ['caring', 'optimism'],\n",
    " ['amusement'],\n",
    " ['curiosity', 'neutrality'],\n",
    " ['excitement'],\n",
    " ['disappointment', 'disapproval'],\n",
    " ['amusement', 'sarcasm'],\n",
    " ['amusement', 'optimism'],\n",
    " ['amusement', 'surprise']] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
