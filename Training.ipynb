{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-17T15:57:35.375095Z","iopub.status.busy":"2024-05-17T15:57:35.374741Z","iopub.status.idle":"2024-05-17T15:57:49.052140Z","shell.execute_reply":"2024-05-17T15:57:49.050842Z","shell.execute_reply.started":"2024-05-17T15:57:35.375065Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'Emotion-Classification' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/AminMohamed-3/Emotion-Classification.git\n","!pip install transformers dataset accelerate -q\n","import sys\n","sys.path.append(\"/kaggle/working/Emotion-Classification\")"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T15:57:49.054802Z","iopub.status.busy":"2024-05-17T15:57:49.054440Z","iopub.status.idle":"2024-05-17T15:57:51.458996Z","shell.execute_reply":"2024-05-17T15:57:51.458062Z","shell.execute_reply.started":"2024-05-17T15:57:49.054770Z"},"trusted":true},"outputs":[],"source":["import torch\n","from Training.dataset import prepare_dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    DataCollatorForTokenClassification,\n","    Trainer\n",")\n","import numpy as np\n","from config import NUM_LABELS\n","import wandb\n","from Training.utils import compute_metrics\n","from Training.utils import MultiLabelTrainer"]},{"cell_type":"markdown","metadata":{},"source":["# Define the model & Prepare Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["model_checkpoint = \"FacebookAI/roberta-base\" # Using a larger model\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","dataset, id2label, label2id = prepare_dataset(tokenizer)\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_checkpoint, num_labels=NUM_LABELS, id2label=id2label, label2id=label2id, problem_type=\"multi_label_classification\"\n",")\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Trainer"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T15:58:21.233664Z","iopub.status.busy":"2024-05-17T15:58:21.232988Z","iopub.status.idle":"2024-05-17T15:58:23.554234Z","shell.execute_reply":"2024-05-17T15:58:23.553437Z","shell.execute_reply.started":"2024-05-17T15:58:21.233627Z"},"metadata":{},"trusted":true},"outputs":[],"source":["data_collator = DataCollatorForTokenClassification(tokenizer, padding=True)\n","\n","# Define the training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=3,  # Training for longer\n","    per_device_train_batch_size=16, # smaller batch size\n","    per_device_eval_batch_size=32,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5, # Using a smaller LR\n","    save_total_limit=10,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    logging_steps=20,\n","    # weight decay\n","    weight_decay=0.01,\n","    #lr_scheduler_type='cosine',\n","    #warmup_ratio=0.1,\n",")\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T16:29:32.406005Z","iopub.status.busy":"2024-05-17T16:29:32.404986Z","iopub.status.idle":"2024-05-17T16:29:32.422235Z","shell.execute_reply":"2024-05-17T16:29:32.421204Z","shell.execute_reply.started":"2024-05-17T16:29:32.405968Z"},"metadata":{},"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"val\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.login(key=\"62f8ddd1a44f05efc5c27f0ee5f22cf5bd70abc5\")\n","trainer.train()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
