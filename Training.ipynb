{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-17T15:57:35.375095Z","iopub.status.busy":"2024-05-17T15:57:35.374741Z","iopub.status.idle":"2024-05-17T15:57:49.052140Z","shell.execute_reply":"2024-05-17T15:57:49.050842Z","shell.execute_reply.started":"2024-05-17T15:57:35.375065Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'Emotion-Classification' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/AminMohamed-3/Emotion-Classification.git\n","!pip install transformers dataset accelerate -q\n","import sys\n","sys.path.append(\"/kaggle/working/Emotion-Classification\")"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T15:57:49.054802Z","iopub.status.busy":"2024-05-17T15:57:49.054440Z","iopub.status.idle":"2024-05-17T15:57:51.458996Z","shell.execute_reply":"2024-05-17T15:57:51.458062Z","shell.execute_reply.started":"2024-05-17T15:57:49.054770Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ossamaak0/miniconda3/envs/main/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","from Training.dataset import prepare_dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    EvalPrediction,\n",")\n","import numpy as np\n","\n","from config import NUM_LABELS"]},{"cell_type":"markdown","metadata":{},"source":["# Define the model & Prepare Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"metadata":{}},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 211225/211225 [00:01<00:00, 143331.68it/s]\n","Map: 100%|██████████| 168980/168980 [00:09<00:00, 18701.40 examples/s]\n","Map: 100%|██████████| 21122/21122 [00:01<00:00, 19521.06 examples/s]\n","Map: 100%|██████████| 21123/21123 [00:01<00:00, 17545.52 examples/s]\n"]}],"source":["model_checkpoint = \"distilbert/distilroberta-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","dataset, id2label, label2id = prepare_dataset(tokenizer)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T15:57:51.460671Z","iopub.status.busy":"2024-05-17T15:57:51.460119Z","iopub.status.idle":"2024-05-17T15:57:52.981349Z","shell.execute_reply":"2024-05-17T15:57:52.980430Z","shell.execute_reply.started":"2024-05-17T15:57:51.460639Z"},"metadata":{},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\n","    model_checkpoint, num_labels=NUM_LABELS, id2label=id2label, label2id=label2id\n",")\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Trainer"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T15:58:21.233664Z","iopub.status.busy":"2024-05-17T15:58:21.232988Z","iopub.status.idle":"2024-05-17T15:58:23.554234Z","shell.execute_reply":"2024-05-17T15:58:23.553437Z","shell.execute_reply.started":"2024-05-17T15:58:21.233627Z"},"metadata":{},"trusted":true},"outputs":[],"source":["from transformers import Trainer, TrainingArguments, DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True)\n","\n","# Define the training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    save_total_limit=10,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T16:28:50.152079Z","iopub.status.busy":"2024-05-17T16:28:50.151136Z","iopub.status.idle":"2024-05-17T16:28:50.162336Z","shell.execute_reply":"2024-05-17T16:28:50.161075Z","shell.execute_reply.started":"2024-05-17T16:28:50.152044Z"},"metadata":{},"trusted":true},"outputs":[],"source":["from sklearn.metrics import (\n","    precision_score,\n","    recall_score,\n","    f1_score,\n","    accuracy_score,\n","    roc_auc_score,\n",")\n","\n","\n","def multi_label_metrics(preds, labels, threshold=0.5):\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(preds))\n","    # convert all to numpy\n","    probs = probs.cpu().detach().numpy()\n","    y_pred = np.zeros(probs.shape)\n","    y_pred[np.where(probs >= threshold)] = 1\n","    y_true = labels\n","    print(y_true.shape)\n","    print(y_pred.shape)\n","    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=\"macro\")\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average=\"macro\")\n","    recall = recall_score(y_true, y_pred, average=\"macro\")\n","\n","    metrics = {\n","        \"f1\": f1_micro_average,\n","        \"accuracy\": accuracy,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","    }\n","\n","    return metrics\n","\n","\n","def compute_metrics(p: EvalPrediction):\n","    label_ids = p.label_ids[:, :NUM_LABELS]\n","    preds = p.predictions\n","    result = multi_label_metrics(preds=preds, labels=label_ids)\n","    return result"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T16:29:32.406005Z","iopub.status.busy":"2024-05-17T16:29:32.404986Z","iopub.status.idle":"2024-05-17T16:29:32.422235Z","shell.execute_reply":"2024-05-17T16:29:32.421204Z","shell.execute_reply.started":"2024-05-17T16:29:32.405968Z"},"metadata":{},"trusted":true},"outputs":[],"source":["class MultiLabelTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.pop(\"labels\")\n","        labels = labels[:, :NUM_LABELS].float()\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        loss_fn = torch.nn.BCEWithLogitsLoss()\n","        loss = loss_fn(logits, labels)\n","        return (loss, outputs) if return_outputs else loss\n","\n","\n","trainer = MultiLabelTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"test\"],\n","    eval_dataset=dataset[\"val\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["f1: 0.0\n","accuracy: 0.0\n","precision: 0.0\n","recall: 0.0\n"]}],"source":["example = dataset[\"train\"][0]\n","\n","# convert input_ids and attetnion_mask to tensor\n","input_ids = torch.tensor([example[\"input_ids\"]])\n","attention_mask = torch.tensor([example[\"attention_mask\"]])\n","labels = torch.tensor([example[\"labels\"]]).float()\n","\n","# move tensors to device\n","input_ids = input_ids.to(device)\n","attention_mask = attention_mask.to(device)\n","labels = labels.to(device)\n","\n","# get model predictions\n","with torch.no_grad():\n","    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","    logits = outputs.logits\n","\n","# convert logits to probabilities\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(logits)\n","\n","# convert probabilities to labels\n","probs = probs.cpu().numpy()\n","y_pred = np.zeros(probs.shape)\n","y_pred[np.where(probs >= 0.5)] = 1\n","y_true = labels\n","y_true = y_true.cpu().numpy()\n","# get metrics\n","f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=\"micro\")\n","accuracy = accuracy_score(y_true, y_pred)\n","precision = precision_score(y_true, y_pred, average=\"micro\")\n","recall = recall_score(y_true, y_pred, average=\"micro\")\n","\n","\n","print(f\"f1: {f1_micro_average}\")\n","\n","print(f\"accuracy: {accuracy}\")\n","\n","print(f\"precision: {precision}\")\n","\n","print(f\"recall: {recall}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
